name: Mathematical and Physical Validation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Daily validation at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - critical
        - mathematical
        - surface_code
        - decoders

env:
  PYTHON_VERSION: "3.11"
  HYPOTHESIS_SEED: "42"
  PYTHONPATH: "src"
  COVERAGE_FILE: ".coverage"

jobs:
  # Critical mathematical validation - must pass first
  critical-validation:
    name: Critical Mathematical Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov hypothesis black flake8 mypy
        
    - name: Run Critical Tests First
      run: |
        echo "Running critical mathematical tests..."
        echo "Testing d¬≤ = 0 condition..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from ccscv import ChainComplex
        print('‚úì ChainComplex import successful')
        "
        
        echo "Testing homology computation..."
        pytest tests/test_homology.py::TestHomologyCalculator::test_sphere_chain_complex -v --tb=short
        pytest tests/test_homology.py::TestHomologyCalculator::test_torus_chain_complex -v --tb=short
        
        echo "Testing d¬≤ = 0 validation..."
        pytest tests/test_homology.py::TestHomologyCalculator::test_d_squared_zero_validation -v --tb=short
        
        echo "‚úì Critical mathematical tests passed"
        
    - name: Fail Fast on Critical Errors
      if: failure()
      run: |
        echo "‚ùå Critical mathematical tests failed - stopping pipeline"
        echo "This indicates a fundamental mathematical error that must be fixed immediately"
        exit 1

  # Full test matrix across Python versions and OS
  test-matrix:
    name: Test Matrix
    needs: critical-validation
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python-version: [3.11, 3.12]
        os: [ubuntu-latest, macos-latest]
        include:
          - python-version: 3.11
            os: ubuntu-latest
            coverage: true
            lint: true
            type-check: true
            
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov hypothesis black flake8 mypy
        
    - name: Run Mathematical Validation Tests
      run: |
        echo "Stage 1: Mathematical Validation"
        echo "Testing chain complex axioms..."
        pytest tests/test_chain_complex.py -v --tb=short --durations=10
        
        echo "Testing homology computation..."
        pytest tests/test_homology.py -v --tb=short --durations=10
        
        echo "Testing Smith Normal Form..."
        pytest tests/test_homology.py::TestSmithNormalForm -v --tb=short
        
    - name: Run Surface Code Validation Tests
      run: |
        echo "Stage 2: Surface Code Validation"
        echo "Testing stabilizer formalism..."
        pytest tests/test_surface_code.py::TestStabilizersAndLogicals -v --tb=short
        
        echo "Testing logical operator structure..."
        pytest tests/test_surface_code.py::TestLogicalOperators -v --tb=short
        
        echo "Testing cell complex structure..."
        pytest tests/test_surface_code.py::TestCellComplexStructure -v --tb=short
        
    - name: Run Decoder Validation Tests
      run: |
        echo "Stage 3: Decoder Validation"
        echo "Testing threshold behavior..."
        pytest tests/test_decoders.py::TestThresholdBehavior -v --tb=short
        
        echo "Testing distance scaling..."
        pytest tests/test_decoders.py::TestDistanceScaling -v --tb=short
        
        echo "Testing MWPM correctness..."
        pytest tests/test_decoders.py::TestMWPMDecoder -v --tb=short
        
    - name: Run Property-Based Tests
      run: |
        echo "Stage 4: Property-Based Testing"
        echo "Running hypothesis tests with deterministic seed..."
        HYPOTHESIS_SEED=42 pytest tests/ --hypothesis-profile=ci -v --tb=short
        
    - name: Run Integration Tests
      run: |
        echo "Stage 5: Integration Testing"
        echo "Testing complete workflows..."
        pytest tests/ -k "integration or workflow" -v --tb=short
        
    - name: Run Full Test Suite with Coverage
      if: matrix.coverage == true
      run: |
        echo "Running full test suite with coverage..."
        pytest tests/ -v --cov=ccscv --cov-report=xml --cov-report=html --cov-report=term-missing
        
    - name: Upload coverage to Codecov
      if: matrix.coverage == true
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Run Linting
      if: matrix.lint == true
      run: |
        echo "Running code linting..."
        black --check --diff src/ tests/ examples/
        flake8 src/ tests/ examples/ --max-line-length=100 --extend-ignore=E203,W503
        
    - name: Run Type Checking
      if: matrix.type-check == true
      run: |
        echo "Running type checking..."
        mypy src/ --ignore-missing-imports --no-strict-optional

  # Performance and regression testing
  performance-tests:
    name: Performance and Regression Tests
    needs: critical-validation
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark memory-profiler
        
    - name: Run Performance Benchmarks
      run: |
        echo "Running performance benchmarks..."
        pytest tests/ -m "benchmark" --benchmark-only --benchmark-sort=mean
        
    - name: Run Memory Profiling Tests
      run: |
        echo "Running memory profiling tests..."
        pytest tests/ -k "memory or large" -v --tb=short
        
    - name: Run Scalability Tests
      run: |
        echo "Running scalability tests..."
        pytest tests/ -k "scalability or large_chain" -v --tb=short

  # Documentation and validation
  documentation-validation:
    name: Documentation and Schema Validation
    needs: critical-validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jsonschema
        
    - name: Validate JSON Schema
      run: |
        echo "Validating JSON schema..."
        python -c "
        import json
        import jsonschema
        from jsonschema import validate
        
        # Load schema
        with open('data/schema/chain_complex.schema.json', 'r') as f:
            schema = json.load(f)
        
        # Load example data
        with open('data/examples/toric_d3.json', 'r') as f:
            example = json.load(f)
        
        # Validate
        validate(instance=example, schema=schema)
        print('‚úì JSON schema validation passed')
        "
        
    - name: Validate Example Data
      run: |
        echo "Validating example data files..."
        python -c "
        import json
        import os
        
        examples_dir = 'data/examples'
        for filename in os.listdir(examples_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(examples_dir, filename)
                with open(filepath, 'r') as f:
                    data = json.load(f)
                print(f'‚úì {filename} is valid JSON')
        "
        
    - name: Check Documentation Links
      run: |
        echo "Checking documentation links..."
        # Check for broken internal links in markdown files
        find docs/ -name "*.md" -exec grep -l "\[.*\](" {} \; | while read file; do
          echo "Checking links in $file"
          grep -o "\[.*\]([^)]*)" "$file" | sed 's/.*(\([^)]*\))/\1/' | while read link; do
            if [[ "$link" == http* ]]; then
              echo "External link: $link"
            elif [[ "$link" == \#* ]]; then
              echo "Anchor link: $link"
            else
              if [ ! -f "$link" ] && [ ! -f "docs/$link" ]; then
                echo "Warning: Broken link in $file: $link"
              fi
            fi
          done
        done

  # Final validation and reporting
  final-validation:
    name: Final Validation and Reporting
    needs: [test-matrix, performance-tests, documentation-validation]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
        
    - name: Generate Final Test Report
      run: |
        echo "Generating final test report..."
        pytest tests/ --cov=ccscv --cov-report=term-missing --cov-report=html --junitxml=test-results.xml
        
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          test-results.xml
          htmlcov/
          .coverage
          
    - name: Check Test Results
      run: |
        echo "Checking test results..."
        if [ -f "test-results.xml" ]; then
          echo "‚úì Test results generated successfully"
        else
          echo "‚ùå Test results not generated"
          exit 1
        fi
        
    - name: Final Validation Summary
      run: |
        echo "=== Final Validation Summary ==="
        echo "‚úì Critical mathematical validation passed"
        echo "‚úì Test matrix completed across Python versions and OS"
        echo "‚úì Performance and regression tests completed"
        echo "‚úì Documentation and schema validation completed"
        echo "‚úì All validation stages completed successfully"
        
        if [ "${{ needs.test-matrix.result }}" == "success" ] && \
           [ "${{ needs.performance-tests.result }}" == "success" ] && \
           [ "${{ needs.documentation-validation.result }}" == "success" ]; then
          echo "üéâ All validation stages passed successfully!"
        else
          echo "‚ùå Some validation stages failed"
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Performance Tests: ${{ needs.performance-tests.result }}"
          echo "Documentation Validation: ${{ needs.documentation-validation.result }}"
          exit 1
        fi
