name: Mathematical and Physical Validation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Daily validation at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - critical
        - mathematical
        - surface_code
        - decoders

env:
  PYTHON_VERSION: "3.11"
  HYPOTHESIS_SEED: "42"
  PYTHONPATH: "src"
  COVERAGE_FILE: ".coverage"

jobs:
  # Critical mathematical validation - must pass first
  critical-validation:
    name: Critical Mathematical Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov hypothesis black flake8 mypy
        
    - name: Run Critical Tests First
      run: |
        echo "Running critical mathematical tests..."
        echo "Testing d² = 0 condition..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from ccscv import ChainComplex
        print('✓ ChainComplex import successful')
        "
        
        echo "Testing homology computation..."
        pytest tests/test_homology.py::TestHomologyCalculator::test_sphere_chain_complex -v --tb=short
        pytest tests/test_homology.py::TestHomologyCalculator::test_torus_chain_complex -v --tb=short
        
        echo "Testing d² = 0 validation..."
        pytest tests/test_homology.py::TestHomologyCalculator::test_d_squared_zero_validation -v --tb=short
        
        echo "✓ Critical mathematical tests passed"
        
    - name: Fail Fast on Critical Errors
      if: failure()
      run: |
        echo "❌ Critical mathematical tests failed - stopping pipeline"
        echo "This indicates a fundamental mathematical error that must be fixed immediately"
        exit 1

  # Full test matrix across Python versions and OS
  test-matrix:
    name: Test Matrix
    needs: critical-validation
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python-version: [3.11, 3.12]
        os: [ubuntu-latest, macos-latest]
        include:
          - python-version: 3.11
            os: ubuntu-latest
            coverage: true
            lint: true
            type-check: true
            
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov hypothesis black flake8 mypy
        
    - name: Run Mathematical Validation Tests
      run: |
        echo "Stage 1: Mathematical Validation"
        echo "Testing chain complex axioms..."
        pytest tests/test_chain_complex.py -v --tb=short --durations=10
        
        echo "Testing homology computation..."
        pytest tests/test_homology.py -v --tb=short --durations=10
        
        echo "Testing Smith Normal Form..."
        pytest tests/test_homology.py::TestSmithNormalForm -v --tb=short
        
    - name: Run Surface Code Validation Tests
      run: |
        echo "Stage 2: Surface Code Validation"
        echo "Testing stabilizer formalism..."
        pytest tests/test_surface_code.py::TestStabilizersAndLogicals -v --tb=short
        
        echo "Testing logical operator structure..."
        pytest tests/test_surface_code.py::TestLogicalOperators -v --tb=short
        
        echo "Testing cell complex structure..."
        pytest tests/test_surface_code.py::TestCellComplexStructure -v --tb=short
        
    - name: Run Decoder Validation Tests
      run: |
        echo "Stage 3: Decoder Validation"
        echo "Testing threshold behavior..."
        pytest tests/test_decoders.py::TestThresholdBehavior -v --tb=short
        
        echo "Testing distance scaling..."
        pytest tests/test_decoders.py::TestDistanceScaling -v --tb=short
        
        echo "Testing MWPM correctness..."
        pytest tests/test_decoders.py::TestMWPMDecoder -v --tb=short
        
    - name: Run Property-Based Tests
      run: |
        echo "Stage 4: Property-Based Testing"
        echo "Running hypothesis tests with deterministic seed..."
        HYPOTHESIS_SEED=42 pytest tests/ --hypothesis-profile=ci -v --tb=short
        
    - name: Run Integration Tests
      run: |
        echo "Stage 5: Integration Testing"
        echo "Testing complete workflows..."
        pytest tests/ -k "integration or workflow" -v --tb=short
        
    - name: Run Full Test Suite with Coverage
      if: matrix.coverage == true
      run: |
        echo "Running full test suite with coverage..."
        pytest tests/ -v --cov=ccscv --cov-report=xml --cov-report=html --cov-report=term-missing
        
    - name: Upload coverage to Codecov
      if: matrix.coverage == true
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Run Linting
      if: matrix.lint == true
      run: |
        echo "Running code linting..."
        black --check --diff src/ tests/ examples/
        flake8 src/ tests/ examples/ --max-line-length=100 --extend-ignore=E203,W503
        
    - name: Run Type Checking
      if: matrix.type-check == true
      run: |
        echo "Running type checking..."
        mypy src/ --ignore-missing-imports --no-strict-optional

  # Performance and regression testing
  performance-tests:
    name: Performance and Regression Tests
    needs: critical-validation
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark memory-profiler
        
    - name: Run Performance Benchmarks
      run: |
        echo "Running performance benchmarks..."
        pytest tests/ -m "benchmark" --benchmark-only --benchmark-sort=mean
        
    - name: Run Memory Profiling Tests
      run: |
        echo "Running memory profiling tests..."
        pytest tests/ -k "memory or large" -v --tb=short
        
    - name: Run Scalability Tests
      run: |
        echo "Running scalability tests..."
        pytest tests/ -k "scalability or large_chain" -v --tb=short

  # Documentation and validation
  documentation-validation:
    name: Documentation and Schema Validation
    needs: critical-validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jsonschema
        
    - name: Validate JSON Schema
      run: |
        echo "Validating JSON schema..."
        python -c "
        import json
        import jsonschema
        from jsonschema import validate
        
        # Load schema
        with open('data/schema/chain_complex.schema.json', 'r') as f:
            schema = json.load(f)
        
        # Load example data
        with open('data/examples/toric_d3.json', 'r') as f:
            example = json.load(f)
        
        # Validate
        validate(instance=example, schema=schema)
        print('✓ JSON schema validation passed')
        "
        
    - name: Validate Example Data
      run: |
        echo "Validating example data files..."
        python -c "
        import json
        import os
        
        examples_dir = 'data/examples'
        for filename in os.listdir(examples_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(examples_dir, filename)
                with open(filepath, 'r') as f:
                    data = json.load(f)
                print(f'✓ {filename} is valid JSON')
        "
        
    - name: Check Documentation Links
      run: |
        echo "Checking documentation links..."
        # Check for broken internal links in markdown files
        find docs/ -name "*.md" -exec grep -l "\[.*\](" {} \; | while read file; do
          echo "Checking links in $file"
          grep -o "\[.*\]([^)]*)" "$file" | sed 's/.*(\([^)]*\))/\1/' | while read link; do
            if [[ "$link" == http* ]]; then
              echo "External link: $link"
            elif [[ "$link" == \#* ]]; then
              echo "Anchor link: $link"
            else
              if [ ! -f "$link" ] && [ ! -f "docs/$link" ]; then
                echo "Warning: Broken link in $file: $link"
              fi
            fi
          done
        done

  # Final validation and reporting
  final-validation:
    name: Final Validation and Reporting
    needs: [test-matrix, performance-tests, documentation-validation]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
        
    - name: Generate Final Test Report
      run: |
        echo "Generating final test report..."
        pytest tests/ --cov=ccscv --cov-report=term-missing --cov-report=html --junitxml=test-results.xml
        
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          test-results.xml
          htmlcov/
          .coverage
          
    - name: Check Test Results
      run: |
        echo "Checking test results..."
        if [ -f "test-results.xml" ]; then
          echo "✓ Test results generated successfully"
        else
          echo "❌ Test results not generated"
          exit 1
        fi
        
    - name: Final Validation Summary
      run: |
        echo "=== Final Validation Summary ==="
        echo "✓ Critical mathematical validation passed"
        echo "✓ Test matrix completed across Python versions and OS"
        echo "✓ Performance and regression tests completed"
        echo "✓ Documentation and schema validation completed"
        echo "✓ All validation stages completed successfully"
        
        if [ "${{ needs.test-matrix.result }}" == "success" ] && \
           [ "${{ needs.performance-tests.result }}" == "success" ] && \
           [ "${{ needs.documentation-validation.result }}" == "success" ]; then
          echo "🎉 All validation stages passed successfully!"
        else
          echo "❌ Some validation stages failed"
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Performance Tests: ${{ needs.performance-tests.result }}"
          echo "Documentation Validation: ${{ needs.documentation-validation.result }}"
          exit 1
        fi
